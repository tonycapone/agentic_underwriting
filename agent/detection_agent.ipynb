{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0f5662",
   "metadata": {},
   "source": [
    "\n",
    "# Impairment Detection Agent\n",
    "\n",
    "This notebook shows, step‑by‑step, how the Strands agent ingests XML feeds, identifies impairments,\n",
    "pulls scoring‑factor names from the Knowledge‑Base markdown, and emits the JSON payload\n",
    "expected by Work‑stream 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cee47e",
   "metadata": {},
   "source": [
    "## Installation and Dependencies\n",
    "\n",
    "**What:** Install the core libraries needed for the detection agent.\n",
    "\n",
    "**Why:** \n",
    "- `boto3` - Provides AWS SDK access to Bedrock LLMs and knowledge bases\n",
    "- `strands-agents` - The agent framework that orchestrates tool calls and LLM interactions\n",
    "- `numpy` - Used for vector similarity calculations when using local knowledge base\n",
    "- `lxml` - Parses XML data feeds (application, RX, labs, MIB)\n",
    "\n",
    "These dependencies allow the agent to ingest structured insurance data, query underwriting guidelines, and reason about medical impairments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3 strands-agents numpy lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f4d594",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**What:** Set up the model, knowledge base, and data source paths.\n",
    "\n",
    "**Why:**\n",
    "- **Flexible Knowledge Base**: Toggle between local markdown files (for development/demos) and AWS Bedrock Knowledge Base (for production). Set `kb_id = None` to use local files.\n",
    "- **Model Selection**: Use Claude 3.7 Sonnet for its advanced reasoning capabilities needed to detect subtle medical patterns across multiple data sources.\n",
    "- **Embedding Model**: Amazon Titan embeddings power semantic search across underwriting guidelines when using local knowledge base.\n",
    "- **Mock Data Switching**: Easily switch between test cases (diabetes_cardiovascular vs hypertension) to validate agent behavior across different clinical scenarios.\n",
    "\n",
    "This configuration makes the notebook portable - it can run locally with markdown files or connect to cloud infrastructure without code changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, boto3\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from lxml import etree\n",
    "from strands import Agent, tool\n",
    "\n",
    "# ---- Set these before running locally ----\n",
    "# Knowledge base configuration - uncomment the line below to use Bedrock Knowledge Base instead of local files\n",
    "#kb_id = 'YSWIGPQHRJ'\n",
    "kb_id = None  # Reset to None to ensure clean state\n",
    "\n",
    "model_id = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\n",
    "embedding_model_id = 'amazon.titan-embed-text-v2:0'\n",
    "\n",
    "# Mock data configuration\n",
    "# mock_data_path = \"../mock_data/hypertension\"\n",
    "mock_data_path = \"../mock_data/diabetes_cardiovascular\"\n",
    "\n",
    "# Local knowledge base path\n",
    "local_kb_path = \"../underwriting-manual\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509745f",
   "metadata": {},
   "source": [
    "## Local Knowledge Base Setup\n",
    "\n",
    "**What:** Create an in-memory vector database from markdown underwriting guidelines.\n",
    "\n",
    "**Why:**\n",
    "- **Development Independence**: Run the agent without AWS dependencies - perfect for demos, testing, or air-gapped environments.\n",
    "- **Semantic Search**: Convert each markdown file into an embedding vector, allowing the agent to find the most relevant underwriting guidelines (e.g., searching \"high blood pressure\" matches the hypertension.md file).\n",
    "- **Cost Efficiency**: Avoid Bedrock Knowledge Base charges during development and testing.\n",
    "- **Transparency**: See exactly which documents the agent is using - helpful for debugging and understanding agent behavior.\n",
    "\n",
    "The `cosine_similarity` function measures how closely a search query matches each document's semantic meaning, not just keyword matching. This mirrors how a human underwriter would recognize that \"elevated A1C\" relates to diabetes guidelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178afc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Knowledge Base Setup\n",
    "local_kb_store = None\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def create_embedding(text):\n",
    "    \"\"\"Create embedding using Amazon Titan model\"\"\"\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=embedding_model_id,\n",
    "        body=json.dumps({\"inputText\": text})\n",
    "    )\n",
    "    embedding = json.loads(response['body'].read())['embedding']\n",
    "    return np.array(embedding)\n",
    "\n",
    "def load_local_knowledge_base():\n",
    "    \"\"\"Load markdown files from local underwriting manual and create embeddings\"\"\"\n",
    "    global local_kb_store\n",
    "    \n",
    "    if 'kb_id' in globals() and kb_id is not None:\n",
    "        print(\"Bedrock KB configured, skipping local KB loading...\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading local knowledge base from {local_kb_path}...\")\n",
    "    \n",
    "    kb_documents = []\n",
    "    \n",
    "    # Find all markdown files recursively in the underwriting manual directory\n",
    "    if not os.path.exists(local_kb_path):\n",
    "        print(f\"Warning: Local KB path {local_kb_path} does not exist\")\n",
    "        return\n",
    "    \n",
    "    for root, dirs, files in os.walk(local_kb_path):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith('.md'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                # Get relative path for better display\n",
    "                rel_path = os.path.relpath(file_path, local_kb_path)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    print(f\"✓ Loading {rel_path} ({len(content)} chars)\")\n",
    "                    \n",
    "                    # Create embedding for the document\n",
    "                    embedding = create_embedding(content)\n",
    "                    \n",
    "                    kb_documents.append({\n",
    "                        'filename': rel_path,  # Use relative path to preserve directory structure\n",
    "                        'content': content,\n",
    "                        'embedding': embedding\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"✗ Error loading {rel_path}: {e}\")\n",
    "    \n",
    "    local_kb_store = kb_documents\n",
    "    print(f\"Local knowledge base loaded with {len(kb_documents)} documents\")\n",
    "\n",
    "# Load the local knowledge base if kb_id is not defined or None\n",
    "if 'kb_id' not in globals() or kb_id is None:\n",
    "    load_local_knowledge_base()\n",
    "else:\n",
    "    print(\"Using Bedrock Knowledge Base\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e55fb0",
   "metadata": {},
   "source": [
    "## Agent Tools - Part 1: Scratch Pad\n",
    "\n",
    "**What:** An optional tool that sets up a temporary storage tool that will allow the agent maintain working memory across multiple reasoning steps.\n",
    "\n",
    "**Why:**\n",
    "The impairment detection process is complex and multi-step:\n",
    "1. Scan all data sources to identify potential impairments\n",
    "2. For each impairment, search the knowledge base\n",
    "3. Extract scoring factors from guidelines\n",
    "4. Cross-reference data feeds to find values for those factors\n",
    "5. Compile evidence from multiple sources\n",
    "\n",
    "**Without a scratch pad**, the agent would have to hold all this information in its context window and might lose track of what it's already discovered. The scratch pad lets it:\n",
    "- Store a running list of impairments found\n",
    "- Track which impairments have been fully analyzed\n",
    "- Build up scoring factors and evidence incrementally\n",
    "\n",
    "This is analogous to how a human underwriter uses notes while reviewing a case file.\n",
    "\n",
    "*Note: This tool may or may not be needed depending on the context length of the model you are using and how long the agent needs to run.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected tools that follow Strands documentation patterns\n",
    "\n",
    "@tool\n",
    "def scratch_fixed(action: str, key: str, value=None, agent=None):\n",
    "    \"\"\"Tool for temporary storage during agent execution - uses agent.state properly\"\"\"\n",
    "    # Use agent state for persistence across tool calls\n",
    "    scratch_data = agent.state.get('scratch_pad') or {}\n",
    "    \n",
    "    if action == 'append':\n",
    "        if key not in scratch_data:\n",
    "            scratch_data[key] = []\n",
    "        scratch_data[key].append(value)\n",
    "    elif action == 'set':\n",
    "        scratch_data[key] = value\n",
    "    elif action == 'get':\n",
    "        return scratch_data.get(key)\n",
    "    \n",
    "    # Save back to agent state\n",
    "    agent.state.set('scratch_pad', scratch_data)\n",
    "    return 'ok'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885526d6",
   "metadata": {},
   "source": [
    "## Agent Tools - Part 2: Knowledge Base Search\n",
    "\n",
    "**What:** A tool that retrieves underwriting guidelines for specific medical conditions.\n",
    "\n",
    "**Why:**\n",
    "The agent needs access to authoritative underwriting rules to:\n",
    "- **Identify Scoring Factors**: Each impairment has specific factors that affect risk (e.g., for diabetes: A1C level, duration, complications)\n",
    "- **Understand Severity Thresholds**: Guidelines define what values are considered mild vs. severe (e.g., A1C < 7% vs. > 9%)\n",
    "- **Know What Evidence to Look For**: The guidelines tell the agent which lab values, medications, or clinical findings are relevant\n",
    "\n",
    "**Dual-Mode Design**: This function automatically switches between:\n",
    "- **Local Mode**: Searches markdown files using vector similarity (useful for development)\n",
    "- **Bedrock Mode**: Queries AWS Bedrock Knowledge Base (production-ready, managed service)\n",
    "\n",
    "Think of this as the agent consulting the underwriting manual - just like a human underwriter would reference rating tables and guidelines when evaluating a condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16944688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kb_rt = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "@tool\n",
    "def kb_search(canonical_term: str):\n",
    "    \"\"\"Return markdown for the top KB hit from either local or Bedrock knowledge base.\"\"\"\n",
    "    \n",
    "    if ('kb_id' not in globals() or kb_id is None) and local_kb_store:\n",
    "        # Use local knowledge base\n",
    "        print(f\"Searching local KB for: {canonical_term}\")\n",
    "        \n",
    "        # Create embedding for the search query\n",
    "        query_embedding = create_embedding(canonical_term)\n",
    "        \n",
    "        # Find the most similar document\n",
    "        best_match = None\n",
    "        best_similarity = -1\n",
    "        \n",
    "        for doc in local_kb_store:\n",
    "            similarity = cosine_similarity(query_embedding, doc['embedding'])\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_match = doc\n",
    "        \n",
    "        if best_match:\n",
    "            print(f\"Best match: {best_match['filename']} (similarity: {best_similarity:.3f})\")\n",
    "            return best_match['content']\n",
    "        else:\n",
    "            return \"No matching documents found in local knowledge base.\"\n",
    "    \n",
    "    else:\n",
    "        # Use Bedrock Knowledge Base\n",
    "        print(f\"Searching Bedrock KB for: {canonical_term}\")\n",
    "        resp = kb_rt.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={'text': canonical_term},\n",
    "            retrievalConfiguration={'vectorSearchConfiguration': {'numberOfResults': 1}}\n",
    "        )\n",
    "        print(resp)\n",
    "        # According to official AWS documentation, the field is 'text', not 'text_markdown'\n",
    "        return resp['retrievalResults'][0]['content']['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657116f",
   "metadata": {},
   "source": [
    "## Agent System Prompt\n",
    "\n",
    "**What:** Instructions that define the agent's role, workflow, and output format.\n",
    "\n",
    "**Why:**\n",
    "This prompt orchestrates a sophisticated multi-step reasoning process that mirrors how experienced underwriters work:\n",
    "\n",
    "**Step 1: Initial Scan** - \"What conditions does this applicant have?\"\n",
    "- Review application questionnaire answers\n",
    "- Check prescription history for medications\n",
    "- Analyze lab results for abnormal values\n",
    "- Review MIB records for prior insurance applications\n",
    "\n",
    "**Step 2: Per-Impairment Deep Dive** - \"How do I score this condition?\"\n",
    "- Query the knowledge base for relevant guidelines\n",
    "- Extract the specific scoring factors needed (e.g., A1C, duration, complications)\n",
    "\n",
    "**Step 3: Evidence Gathering** - \"What data supports this assessment?\"\n",
    "- Cross-reference all data sources\n",
    "- Find values for each scoring factor\n",
    "- Document where each piece of evidence came from\n",
    "\n",
    "**Step 4: Structured Output** - \"Package findings for the scoring agent\"\n",
    "- Format results as JSON with impairment ID, scoring factors, and evidence\n",
    "- This payload becomes input for Workstream 4 (risk scoring)\n",
    "\n",
    "The prompt emphasizes **deduplication** because the same condition often appears in multiple sources (e.g., diabetes mentioned in application, RX history, labs, and MIB). The agent must consolidate these into a single coherent assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab333ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT = \"\"\"You are a senior life insurance underwriter. Your job is to analyze the data stream for an application and identify impairments, \n",
    "scoring factors (based on the knowledge base), and evidences for those impairments. \n",
    "1. Scan the XML feeds (application, Rx, labs, MIB) for impairment evidence and write out an initial list of impairments.\n",
    "Then for each impairment in your scratch pad, do the following:\n",
    "2. Call kb_search() once and treat the markdown returned as authoritative.\n",
    "3. Use the ratings tables in the returned markdown to determine a list of \"scoring factors\" are required to completely score that impairment and write them out. \n",
    "4. Search through the XML feeds to consolidate the values for each scoring factor, and the list of evidence for that impairment. \n",
    "5. Write out the scoring factors and evidence for that impairment.\n",
    "\n",
    "Repeat this process for each impairment you find. Deduplicate any impairment that is found in multiple XML feeds into one listng. \n",
    "\n",
    "Once you have completed this process for all impairments, return the following JSON:\n",
    "```json   \n",
    "   [\n",
    "     {\n",
    "       \"impairment_id\": \"diabetes\",\n",
    "       \"scoring_factors\": {\"A1C\": 8.2, \"Neuropathy\": true},\n",
    "       \"evidence\": [\"Rx: insulin …\", \"Lab: A1C 8.2 %\"]\n",
    "     }\n",
    "   ]\n",
    "```\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1faa503",
   "metadata": {},
   "source": [
    "## Test Utility (Optional)\n",
    "\n",
    "**What:** A simple function to verify the local knowledge base is working correctly.\n",
    "\n",
    "**Why:**\n",
    "Before running the full agent, it's useful to validate:\n",
    "- All markdown files loaded successfully\n",
    "- Embeddings were created properly\n",
    "- Semantic search returns relevant documents\n",
    "\n",
    "Uncomment the last line (`test_local_kb()`) to see:\n",
    "- Which documents are in the knowledge base\n",
    "- What gets returned when searching for \"diabetes\"\n",
    "- Whether the similarity scoring is working\n",
    "\n",
    "This is particularly helpful when troubleshooting or adding new underwriting guidelines to the knowledge base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8720cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test local knowledge base functionality\n",
    "def test_local_kb():\n",
    "    \"\"\"Test the local knowledge base search functionality\"\"\"\n",
    "    if ('kb_id' not in globals() or kb_id is None) and local_kb_store:\n",
    "        print(f\"Local KB contains {len(local_kb_store)} documents:\")\n",
    "        for doc in local_kb_store:\n",
    "            print(f\"  - {doc['filename']}\")\n",
    "        \n",
    "        # Test a search\n",
    "        print(\"\\nTesting search for 'diabetes':\")\n",
    "        result = kb_search(\"diabetes\")\n",
    "        print(f\"Result length: {len(result)} characters\")\n",
    "        print(\"First 200 characters:\", result[:200] + \"...\" if len(result) > 200 else result)\n",
    "    else:\n",
    "        print(\"Local KB not available or Bedrock KB is configured\")\n",
    "\n",
    "# Uncomment to test the local knowledge base\n",
    "# test_local_kb()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7dc414",
   "metadata": {},
   "source": [
    "## Load Mock Application Data\n",
    "\n",
    "**What:** Read synthetic JSON files that simulate real insurance data feeds.\n",
    "\n",
    "**Why:**\n",
    "In production, an underwriter receives data from multiple sources:\n",
    "- **Application JSON** - Applicant demographics, medical history questionnaire, coverage details\n",
    "- **Prescription History (RX)** - Medication fills from pharmacy databases (IntelliScript)\n",
    "- **Lab Results** - Blood work, urinalysis, diagnostic tests\n",
    "- **MIB Response** - Medical Information Bureau records from prior insurance applications\n",
    "- **RX CSV** - Alternative prescription data format (sometimes CSV, sometimes XML)\n",
    "\n",
    "**Why JSON instead of XML?** The mock data has been converted to JSON with:\n",
    "- Masked company names and addresses (to anonymize the source)\n",
    "- Preserved clinical values (labs, medications, dosages, indications)\n",
    "- Randomized structure (to prevent exact schema matching)\n",
    "\n",
    "This lets us test with realistic data scenarios:\n",
    "- **diabetes_cardiovascular/** - Complex case with Type 2 Diabetes, hypertension, and cardiovascular risk factors\n",
    "- **hypertension/** - Simpler case with controlled blood pressure and excellent labs\n",
    "\n",
    "The agent must handle both scenarios and correctly extract impairments regardless of data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mock data from ../mock_data directory\n",
    "def load_mock_data():\n",
    "    import os\n",
    "    \n",
    "    \n",
    "    mock_data = {}\n",
    "    \n",
    "    # Load all XML files from specified directory\n",
    "    # Load all XML files from the specified directory\n",
    "    files = {}\n",
    "    for filename in os.listdir(mock_data_path):\n",
    "        if filename.lower().endswith('.json'):\n",
    "            key = filename.replace('.json', '')\n",
    "            files[key] = filename\n",
    "    \n",
    "    for key, filename in files.items():\n",
    "        file_path = os.path.join(mock_data_path, filename)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                mock_data[key] = f.read()\n",
    "            print(f\"✓ Loaded {filename}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"✗ Could not find {filename}\")\n",
    "            mock_data[key] = ''\n",
    "    \n",
    "    return mock_data\n",
    "\n",
    "# Load the mock data\n",
    "mock_data = load_mock_data()\n",
    "print(f\"\\nLoaded {len([v for v in mock_data.values() if v])} files successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1788c8",
   "metadata": {},
   "source": [
    "## Initialize the Detection Agent\n",
    "\n",
    "**What:** Create an Agent instance with the system prompt and knowledge base search tool.\n",
    "\n",
    "**Why:**\n",
    "The Strands Agent framework connects three critical components:\n",
    "\n",
    "1. **System Prompt** - Defines the agent's reasoning workflow and output format\n",
    "2. **Tools** - Gives the agent the ability to search knowledge bases (the `kb_search` function)\n",
    "3. **Model** - The LLM (Claude 3.7 Sonnet) that performs the reasoning\n",
    "\n",
    "When the agent runs, it will:\n",
    "- Read the system prompt to understand its task\n",
    "- Analyze the data feeds provided\n",
    "- Decide when to call `kb_search()` to retrieve underwriting guidelines\n",
    "- Reason about the results and format the final JSON output\n",
    "\n",
    "This is the \"brain\" of the detection system - the orchestrator that decides what to do and when.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated detector with corrected tools and message handling\n",
    "detector = Agent(\n",
    "    system_prompt=PROMPT,\n",
    "    tools=[kb_search],\n",
    "    model=model_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8c164",
   "metadata": {},
   "source": [
    "## Run Detection Function\n",
    "\n",
    "**What:** A utility function that packages data feeds and calls the agent.\n",
    "\n",
    "**Why:**\n",
    "This function provides a clean interface to:\n",
    "- **Use mock data by default** - Makes testing easy without manually loading files\n",
    "- **Support custom data** - Can override with specific JSON strings if needed\n",
    "- **Extract JSON output** - Parses the agent's response and handles markdown code blocks\n",
    "\n",
    "**The workflow:**\n",
    "1. Gather all data feeds (application, RX, labs, MIB) into a single message\n",
    "2. Send to the agent for analysis\n",
    "3. Agent performs multi-step reasoning (scan → search KB → extract factors → gather evidence)\n",
    "4. Parse the returned JSON (handles cases where agent wraps output in ```json blocks)\n",
    "5. Return structured data ready for Workstream 4 (scoring agent)\n",
    "\n",
    "This abstraction makes it easy to integrate the detection agent into a larger workflow or API endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "def run_detection(application='', rx='', labs='', mib='', use_mock_data=True):\n",
    "    \"\"\"Utility to run the agent in‑notebook\"\"\"\n",
    "    \n",
    "    # Use mock data by default if no specific JSON is provided\n",
    "    if use_mock_data and not any([application, rx, labs, mib]):\n",
    "        feeds = mock_data.copy()\n",
    "        print(\"Using mock data from ../mock_data directory\")\n",
    "    else:\n",
    "        feeds = {\n",
    "            'application': application,\n",
    "            'rx': rx,\n",
    "            'labs': labs,\n",
    "            'mib': mib,\n",
    "        }\n",
    "    \n",
    "    # Create a simple string message with all data feeds\n",
    "    message = f\"Here are the data feeds to analyze for impairments:\\n\\n{feeds}\"\n",
    "    \n",
    "    # Call the agent with a simple string message (correct way according to Strands docs)\n",
    "    res = detector(message)\n",
    "    print(\"Agent response:\")\n",
    "    print(res)\n",
    "    import re\n",
    "\n",
    "    # Extract JSON from between ```json ... ``` tags if present\n",
    "    res_str = str(res)\n",
    "    json_match = re.search(r\"```json\\s*(.*?)\\s*```\", res_str, re.DOTALL)\n",
    "    if json_match:\n",
    "        res_str = json_match.group(1)\n",
    "    else:\n",
    "        # If no markdown code block, try to find JSON array directly\n",
    "        json_match = re.search(r\"\\[.*\\]\", res_str, re.DOTALL)\n",
    "        if json_match:\n",
    "            res_str = json_match.group(0)\n",
    "    \n",
    "    return json.loads(res_str)\n",
    "\n",
    "# Now you can run detection with mock data easily:\n",
    "# sample_output = run_detection()  # Uses mock data automatically\n",
    "# print(json.dumps(sample_output, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233b49a",
   "metadata": {},
   "source": [
    "## Execute Detection on Mock Data\n",
    "\n",
    "**What:** Run the complete impairment detection workflow on the selected test case.\n",
    "\n",
    "**Why:**\n",
    "This is where everything comes together:\n",
    "\n",
    "**Input:** Multiple JSON data feeds from various sources (application, RX history, labs, MIB)\n",
    "\n",
    "**Process:** The agent will:\n",
    "1. Scan all feeds to identify potential impairments\n",
    "2. For each impairment (e.g., diabetes, hypertension):\n",
    "   - Search the knowledge base for relevant guidelines\n",
    "   - Determine what scoring factors are needed\n",
    "   - Find values for those factors across all data sources\n",
    "   - Compile evidence supporting the diagnosis\n",
    "\n",
    "**Output:** Structured JSON listing each impairment with:\n",
    "- `impairment_id` - Canonical name (e.g., \"type2_diabetes\")\n",
    "- `scoring_factors` - Key-value pairs needed for risk scoring (e.g., {\"HbA1c\": 7.2, \"duration_years\": 4})\n",
    "- `evidence` - List of supporting data points with sources\n",
    "\n",
    "**Why this matters:** This output becomes the input to Workstream 4 (scoring agent), which will:\n",
    "- Look up rating tables for each impairment\n",
    "- Apply the scoring factors to calculate debits/credits\n",
    "- Generate a final risk score\n",
    "\n",
    "The detection agent's job is to **find and structure the relevant medical information** so the scoring agent can focus on **applying underwriting rules and calculating risk**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the impairment detection using mock data\n",
    "print(\"=== Running Impairment Detection with Mock Data ===\")\n",
    "print(f\"Knowledge Base Mode: {'Local' if 'kb_id' not in globals() or kb_id is None else 'Bedrock'}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # This will automatically use the mock data from ../mock_data\n",
    "    results = run_detection()\n",
    "    \n",
    "    print(\"\\n=== Detection Results ===\")\n",
    "    print(json.dumps(results, indent=2))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n\\nError running detection: {e}\")\n",
    "    print(\"\\nMake sure:\")\n",
    "    print(\"\\n1. Your AWS credentials are configured\")\n",
    "    if 'kb_id' not in globals() or kb_id is None:\n",
    "        print(\"\\n2. The local underwriting manual files are accessible\")\n",
    "        print(\"\\n3. You have access to the Bedrock embedding model\")\n",
    "    else:\n",
    "        print(\"\\n2. The KB_ID is set correctly\")\n",
    "        print(\"\\n3. You have access to the specified Bedrock model and knowledge base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e4db1",
   "metadata": {},
   "source": [
    "## Summary: What Just Happened?\n",
    "\n",
    "The detection agent just performed sophisticated medical record analysis that would normally require:\n",
    "- **A trained underwriter** to review multiple data sources\n",
    "- **30-60 minutes** to manually cross-reference medications, labs, and medical history\n",
    "- **Deep knowledge** of underwriting guidelines and rating factors\n",
    "\n",
    "**What the agent did automatically:**\n",
    "1. ✅ Identified all medical impairments across 5 different data sources\n",
    "2. ✅ Consulted underwriting guidelines to determine scoring requirements\n",
    "3. ✅ Cross-referenced data to find specific values (A1C, blood pressure, medication adherence, etc.)\n",
    "4. ✅ Compiled evidence trails showing where each data point came from\n",
    "5. ✅ Formatted structured output ready for automated risk scoring\n",
    "\n",
    "**Key advantages of the agentic approach:**\n",
    "- **Consistency**: Same analysis every time, no human variability\n",
    "- **Speed**: Processes cases in seconds instead of minutes\n",
    "- **Completeness**: Never misses relevant data scattered across sources\n",
    "- **Auditability**: Documents evidence chain for compliance and quality review\n",
    "- **Scalability**: Can process thousands of cases without additional headcount\n",
    "\n",
    "**Next step:** Take this output to `scoring_agent.ipynb` to calculate the final risk score using rating tables and underwriting rules.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
